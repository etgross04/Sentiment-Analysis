{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>example_very_unclear</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eeochpb</td>\n",
       "      <td>Literally everywhere. There's nothing especial...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eewnhep</td>\n",
       "      <td>[NAME] and [NAME] may be stronger, but [NAME] ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ee4utnt</td>\n",
       "      <td>Ik I’m crying rn</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>effsrc0</td>\n",
       "      <td>He was cut yesterday, unfortunately</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ee579yx</td>\n",
       "      <td>Nice, I saw them during the Demo and was prett...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  \\\n",
       "0  eeochpb  Literally everywhere. There's nothing especial...   \n",
       "1  eewnhep  [NAME] and [NAME] may be stronger, but [NAME] ...   \n",
       "2  ee4utnt                                   Ik I’m crying rn   \n",
       "3  effsrc0                He was cut yesterday, unfortunately   \n",
       "4  ee579yx  Nice, I saw them during the Demo and was prett...   \n",
       "\n",
       "   example_very_unclear  admiration  amusement  anger  annoyance  approval  \\\n",
       "0                 False           0          0      0          0         0   \n",
       "1                 False           0          0      0          0         0   \n",
       "2                 False           0          0      0          0         0   \n",
       "3                 False           0          0      0          0         0   \n",
       "4                 False           0          1      0          0         1   \n",
       "\n",
       "   caring  confusion  ...  love  nervousness  optimism  pride  realization  \\\n",
       "0       0          0  ...     0            0         0      0            0   \n",
       "1       0          0  ...     0            0         0      0            0   \n",
       "2       0          0  ...     0            0         0      0            0   \n",
       "3       0          0  ...     0            0         0      0            0   \n",
       "4       0          0  ...     0            0         0      0            0   \n",
       "\n",
       "   relief  remorse  sadness  surprise  neutral  \n",
       "0       0        0        0         0        0  \n",
       "1       0        0        0         0        1  \n",
       "2       0        0        1         0        0  \n",
       "3       0        0        0         0        1  \n",
       "4       0        0        0         0        0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('go_emotions_dataset.csv')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Downsample to a manageable subset for quicker experiments\n",
    "MAX_ROWS = 10000\n",
    "df = df.sample(n=min(len(df), MAX_ROWS), random_state=42).reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'text', 'example_very_unclear', 'admiration', 'amusement',\n",
       "       'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity',\n",
       "       'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment',\n",
       "       'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love',\n",
       "       'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse',\n",
       "       'sadness', 'surprise', 'neutral'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_very_unclear : 143\n",
      "admiration   : 829\n",
      "amusement    : 415\n",
      "anger        : 376\n",
      "annoyance    : 633\n",
      "approval     : 806\n",
      "caring       : 277\n",
      "confusion    : 345\n",
      "curiosity    : 479\n",
      "desire       : 191\n",
      "disappointment : 403\n",
      "disapproval  : 544\n",
      "disgust      : 263\n",
      "embarrassment : 126\n",
      "excitement   : 256\n",
      "fear         : 135\n",
      "gratitude    : 556\n",
      "grief        : 12\n",
      "joy          : 378\n",
      "love         : 389\n",
      "nervousness  : 95\n",
      "optimism     : 380\n",
      "pride        : 52\n",
      "realization  : 407\n",
      "relief       : 65\n",
      "remorse      : 114\n",
      "sadness      : 300\n",
      "surprise     : 243\n",
      "neutral      : 2731\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns[2:]:\n",
    "    count = df[col].sum()\n",
    "    print(f\"{col:12s} : {int(count)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. DATA SETUP (Multi-label Emotions)\n",
    "\n",
    "EMOTION_COLS = [\n",
    "    \"admiration\",\n",
    "    \"annoyance\",\n",
    "    \"curiosity\",\n",
    "    \"gratitude\",\n",
    "    \"neutral\",\n",
    "]\n",
    "\n",
    "mask = df[EMOTION_COLS].sum(axis=1) > 0\n",
    "df_condensed = df[mask].reset_index(drop=True)\n",
    "\n",
    "# 2) Features + labels for training\n",
    "X = df_condensed[\"text\"]\n",
    "Y = df_condensed[EMOTION_COLS].values.astype(\"float32\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5104, 31)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_condensed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cogs118a/lib/python3.12/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1 average loss: 0.3714\n",
      "Epoch 2 average loss: 0.2653\n",
      "Epoch 3 average loss: 0.2133\n",
      "Epoch 4 average loss: 0.1563\n",
      "Epoch 5 average loss: 0.1073\n",
      "Epoch 6 average loss: 0.0774\n",
      "Epoch 7 average loss: 0.0542\n",
      "Epoch 8 average loss: 0.0485\n",
      "Epoch 9 average loss: 0.0429\n",
      "Epoch 10 average loss: 0.0374\n",
      "Epoch 11 average loss: 0.0304\n",
      "Epoch 12 average loss: 0.0262\n",
      "Epoch 13 average loss: 0.0218\n",
      "Epoch 14 average loss: 0.0223\n",
      "Epoch 15 average loss: 0.0177\n",
      "Epoch 16 average loss: 0.0168\n",
      "Epoch 17 average loss: 0.0194\n",
      "Epoch 18 average loss: 0.0187\n",
      "Epoch 19 average loss: 0.0152\n",
      "Epoch 20 average loss: 0.0204\n",
      "Epoch 21 average loss: 0.0133\n",
      "Epoch 22 average loss: 0.0113\n",
      "Epoch 23 average loss: 0.0123\n",
      "Epoch 24 average loss: 0.0130\n",
      "Epoch 25 average loss: 0.0129\n",
      "Epoch 26 average loss: 0.0166\n",
      "Epoch 27 average loss: 0.0124\n",
      "Epoch 28 average loss: 0.0124\n",
      "Epoch 29 average loss: 0.0126\n",
      "Epoch 30 average loss: 0.0133\n",
      "Epoch 31 average loss: 0.0123\n",
      "Epoch 32 average loss: 0.0093\n",
      "Epoch 33 average loss: 0.0092\n",
      "Epoch 34 average loss: 0.0101\n",
      "Epoch 35 average loss: 0.0112\n",
      "Epoch 36 average loss: 0.0139\n",
      "Epoch 37 average loss: 0.0129\n",
      "Epoch 38 average loss: 0.0149\n",
      "Epoch 39 average loss: 0.0103\n",
      "Epoch 40 average loss: 0.0086\n",
      "Epoch 41 average loss: 0.0081\n",
      "Epoch 42 average loss: 0.0106\n",
      "Epoch 43 average loss: 0.0121\n",
      "Epoch 44 average loss: 0.0124\n",
      "Epoch 45 average loss: 0.0131\n",
      "Epoch 46 average loss: 0.0105\n",
      "Epoch 47 average loss: 0.0101\n",
      "Epoch 48 average loss: 0.0108\n",
      "Epoch 49 average loss: 0.0087\n",
      "Epoch 50 average loss: 0.0080\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Device setup\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class SarcasmDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=64):\n",
    "        self.texts = list(texts)\n",
    "        self.labels = list(labels)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            str(self.texts[idx]),\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "# 2. MODEL SETUP\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(EMOTION_COLS),\n",
    "    problem_type=\"multi_label_classification\",\n",
    ").to(DEVICE)\n",
    "\n",
    "# 3. TRAINING LOOP\n",
    "train_dataset = SarcasmDataset(X_train, y_train, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "EPOCHS = 50\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} average loss: {avg_loss:.4f}\")\n",
    "\n",
    "# 4. EVALUATION ON HOLD-OUT TEST SET\n",
    "model.eval()\n",
    "preds, targets = [], []\n",
    "test_dataset = SarcasmDataset(X_test, y_test, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        labels = batch['labels'].to(DEVICE)     \n",
    "        inputs = {k: v.to(DEVICE) for k, v in batch.items() if k != 'labels'}\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits                    # (B, 28)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        pred_labels = (probs >= 0.5).int()         # multi-label prediction\n",
    "\n",
    "        preds.append(pred_labels.cpu())\n",
    "        targets.append(labels.cpu().int())\n",
    "\n",
    "preds = torch.vstack(preds).numpy()\n",
    "targets = torch.vstack(targets).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact-match accuracy: 0.6592\n",
      "Micro F1: 0.6926\n",
      "Macro F1: 0.6263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  admiration       0.73      0.64      0.68       184\n",
      "   annoyance       0.42      0.33      0.37       124\n",
      "   curiosity       0.54      0.50      0.52        90\n",
      "   gratitude       0.77      0.82      0.79       113\n",
      "     neutral       0.74      0.79      0.77       536\n",
      "\n",
      "   micro avg       0.70      0.69      0.69      1047\n",
      "   macro avg       0.64      0.62      0.63      1047\n",
      "weighted avg       0.69      0.69      0.69      1047\n",
      " samples avg       0.69      0.69      0.69      1047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# preds, targets already computed as (N, 28) 0/1 arrays\n",
    "# preds = torch.vstack(preds).numpy()\n",
    "# targets = torch.vstack(targets).numpy()\n",
    "\n",
    "# exact-match accuracy (all 28 labels correct)\n",
    "acc = accuracy_score(targets, preds)\n",
    "micro_f1 = f1_score(targets, preds, average=\"micro\", zero_division=0)\n",
    "macro_f1 = f1_score(targets, preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(f\"Exact-match accuracy: {acc:.4f}\")\n",
    "print(f\"Micro F1: {micro_f1:.4f}\")\n",
    "print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "\n",
    "print(classification_report(\n",
    "    targets,\n",
    "    preds,\n",
    "    target_names=EMOTION_COLS,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"text\": X_test.reset_index(drop=True),\n",
    "    \"true_labels\": list(targets),   # 0/1 vectors\n",
    "    \"pred_labels\": list(preds),\n",
    "})\n",
    "comparison_df.head()\n",
    "def decode_rows(arr):\n",
    "    return [\n",
    "        [EMOTION_COLS[i] for i, v in enumerate(row) if v == 1]\n",
    "        for row in arr\n",
    "    ]\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"text\": X_test.reset_index(drop=True),\n",
    "    \"true_emotions\": decode_rows(targets),\n",
    "    \"pred_emotions\": decode_rows(preds),\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact-match accuracy: 0.0350\n",
      "Micro F1: 0.0000\n",
      "Macro F1: 0.0000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact-match accuracy: 0.0350\n",
      "Micro F1: 0.0000\n",
      "Macro F1: 0.0000\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogs118a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
